{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Combined Data Rows:\n",
      "   student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Task 2 - Combined Data Columns:\n",
      "   student_id              name  marks student_id              name  marks\n",
      "0         S1  Danniella Fenton    200         S4  Scarlette Fisher    201\n",
      "1         S2      Ryder Storey    210         S5  Carla Williamson    200\n",
      "2         S3      Bryce Jensen    190         S6       Dante Morse    198\n",
      "3         S4         Ed Bernal    222         S7    Kaiser William    219\n",
      "4         S5       Kwame Morin    199         S8   Madeeha Preston    201\n",
      "\n",
      "Task 3 - Student Data 1 after appending new row:\n",
      "   student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "5         S6  Scarlette Fisher    205\n",
      "\n",
      "Task 4 - Student Data 1 after appending new rows from a dictionary:\n",
      "   student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "5         S6  Scarlette Fisher    205\n",
      "6         S7       New Student    210\n",
      "\n",
      "Task 5 - Merged with Exam Data:\n",
      "   student_id              name  marks  exam_id\n",
      "0         S1  Danniella Fenton    200       23\n",
      "1         S2      Ryder Storey    210       45\n",
      "2         S3      Bryce Jensen    190       12\n",
      "3         S4         Ed Bernal    222       67\n",
      "4         S5       Kwame Morin    199       21\n",
      "5         S7       New Student    210       55\n",
      "6         S4  Scarlette Fisher    201       67\n",
      "7         S5  Carla Williamson    200       21\n",
      "8         S7    Kaiser William    219       55\n",
      "9         S8   Madeeha Preston    201       33\n",
      "\n",
      "Task 6 - Common Column Join:\n",
      "   student_id            name_x  marks_x            name_y  marks_y\n",
      "0         S4         Ed Bernal      222  Scarlette Fisher      201\n",
      "1         S5       Kwame Morin      199  Carla Williamson      200\n",
      "2         S6  Scarlette Fisher      205       Dante Morse      198\n",
      "3         S7       New Student      210    Kaiser William      219\n",
      "\n",
      "Task 7 - Matching Records:\n",
      "   student_id            name_x  marks_x            name_y  marks_y\n",
      "0         S4         Ed Bernal      222  Scarlette Fisher      201\n",
      "1         S5       Kwame Morin      199  Carla Williamson      200\n",
      "2         S6  Scarlette Fisher      205       Dante Morse      198\n",
      "3         S7       New Student      210    Kaiser William      219\n",
      "\n",
      "Task 8 - Left Join:\n",
      "   key1 key2   P   Q    R    S\n",
      "0   K0   K0  P0  Q0   R0   S0\n",
      "1   K0   K1  P1  Q1  NaN  NaN\n",
      "2   K1   K0  P2  Q2   R1   S1\n",
      "3   K1   K0  P2  Q2   R2   S2\n",
      "4   K2   K1  P3  Q3  NaN  NaN\n",
      "\n",
      "Task 9 - Right Join:\n",
      "   key1 key2    P    Q   R   S\n",
      "0   K0   K0   P0   Q0  R0  S0\n",
      "1   K1   K0   P2   Q2  R1  S1\n",
      "2   K1   K0   P2   Q2  R2  S2\n",
      "3   K2   K0  NaN  NaN  R3  S3\n",
      "\n",
      "Task 10 - Multiple Keys Merge:\n",
      "   key1 key2   P   Q   R   S\n",
      "0   K0   K0  P0  Q0  R0  S0\n",
      "1   K1   K0  P2  Q2  R1  S1\n",
      "2   K1   K0  P2  Q2  R2  S2\n",
      "\n",
      "Task 11 - New DataFrame from Series:\n",
      "   student_id              name  marks\n",
      "0         S6  Scarlette Fisher    205\n",
      "\n",
      "Task 12 - Final Combination:\n",
      "   key1 key2   P   Q   R   S\n",
      "1   K1   K0  P2  Q2  R1  S1\n",
      "2   K1   K0  P2  Q2  R2  S2\n",
      "\n",
      "Task 13 - Combined Columns with Different Index:\n",
      "   key1 key2   P   Q key1 key2   R   S\n",
      "0   K0   K0  P0  Q0   K0   K0  R0  S0\n",
      "1   K0   K1  P1  Q1   K1   K0  R1  S1\n",
      "2   K1   K0  P2  Q2   K1   K0  R2  S2\n",
      "3   K2   K1  P3  Q3   K2   K0  R3  S3\n",
      "\n",
      "Task 14 - Merge with Different Columns:\n",
      "   key1 key2    P    Q    R    S\n",
      "0   K0   K0   P0   Q0   R0   S0\n",
      "1   K0   K1   P1   Q1  NaN  NaN\n",
      "2   K1   K0   P2   Q2   R1   S1\n",
      "3   K1   K0   P2   Q2   R2   S2\n",
      "4   K2   K0  NaN  NaN   R3   S3\n",
      "5   K2   K1   P3   Q3  NaN  NaN\n",
      "\n",
      "Task 15 - Combined DataFrame with Filled Nulls:\n",
      "      A    B\n",
      "0  1.0  3.0\n",
      "1  0.0  4.0\n",
      "2  3.0  5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_11332\\196818922.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Test Data Definitions\n",
    "student_data1 = pd.DataFrame({\n",
    "    'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "    'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
    "    'marks': [200, 210, 190, 222, 199]\n",
    "})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "    'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "    'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
    "    'marks': [201, 200, 198, 219, 201]\n",
    "})\n",
    "\n",
    "exam_data = pd.DataFrame({\n",
    "    'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
    "    'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]\n",
    "})\n",
    "\n",
    "data1 = pd.DataFrame({\n",
    "    'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "    'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "    'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "    'Q': ['Q0', 'Q1', 'Q2', 'Q3']\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "    'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "    'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "    'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "    'S': ['S0', 'S1', 'S2', 'S3']\n",
    "})\n",
    "\n",
    "# Task 1\n",
    "combined_data_rows = pd.concat([student_data1, student_data2])\n",
    "print(\"Task 1 - Combined Data Rows:\\n\", combined_data_rows)\n",
    "\n",
    "# Task 2\n",
    "combined_data_cols = pd.concat([student_data1, student_data2], axis=1)\n",
    "print(\"\\nTask 2 - Combined Data Columns:\\n\", combined_data_cols)\n",
    "\n",
    "# Task 3\n",
    "new_row = pd.DataFrame([['S6', 'Scarlette Fisher', 205]], columns=['student_id', 'name', 'marks'])\n",
    "student_data1 = pd.concat([student_data1, new_row], ignore_index=True)\n",
    "print(\"\\nTask 3 - Student Data 1 after appending new row:\\n\", student_data1)\n",
    "\n",
    "# Task 4\n",
    "new_rows_dict = pd.DataFrame([{'student_id': 'S7', 'name': 'New Student', 'marks': 210}])\n",
    "student_data1 = pd.concat([student_data1, new_rows_dict], ignore_index=True)\n",
    "print(\"\\nTask 4 - Student Data 1 after appending new rows from a dictionary:\\n\", student_data1)\n",
    "\n",
    "# Task 5\n",
    "combined_rows = pd.concat([student_data1, student_data2])\n",
    "merged_with_exam = pd.merge(combined_rows, exam_data, on='student_id')\n",
    "print(\"\\nTask 5 - Merged with Exam Data:\\n\", merged_with_exam)\n",
    "\n",
    "# Task 6\n",
    "common_col_join = student_data1.merge(student_data2, on='student_id', how='inner')\n",
    "print(\"\\nTask 6 - Common Column Join:\\n\", common_col_join)\n",
    "\n",
    "# Task 7\n",
    "matching_records = student_data1.merge(student_data2, how='inner', on='student_id')\n",
    "print(\"\\nTask 7 - Matching Records:\\n\", matching_records)\n",
    "\n",
    "# Task 8\n",
    "left_join = data1.merge(data2, on=['key1', 'key2'], how='left')\n",
    "print(\"\\nTask 8 - Left Join:\\n\", left_join)\n",
    "\n",
    "# Task 9\n",
    "right_join = data1.merge(data2, on=['key1', 'key2'], how='right')\n",
    "print(\"\\nTask 9 - Right Join:\\n\", right_join)\n",
    "\n",
    "# Task 10\n",
    "multiple_keys_merge = data1.merge(data2, on=['key1', 'key2'])\n",
    "print(\"\\nTask 10 - Multiple Keys Merge:\\n\", multiple_keys_merge)\n",
    "\n",
    "# Task 11\n",
    "new_dataframe_from_series = new_row\n",
    "print(\"\\nTask 11 - New DataFrame from Series:\\n\", new_dataframe_from_series)\n",
    "\n",
    "# Task 12\n",
    "combined_keys = pd.concat([data1[['key1', 'key2']], data2[['key1', 'key2']]])\n",
    "duplicated_keys = combined_keys[combined_keys.duplicated(keep=False)].drop_duplicates()\n",
    "combination_more_than_once = pd.merge(data1, data2, on=['key1', 'key2'], how='inner')\n",
    "final_combination = combination_more_than_once[combination_more_than_once.duplicated(['key1', 'key2'], keep=False)]\n",
    "print(\"\\nTask 12 - Final Combination:\\n\", final_combination)\n",
    "\n",
    "# Task 13\n",
    "combined_columns_diff_index = pd.concat([data1, data2], axis=1)\n",
    "print(\"\\nTask 13 - Combined Columns with Different Index:\\n\", combined_columns_diff_index)\n",
    "\n",
    "# Task 14\n",
    "merge_diff_columns = pd.merge(data1, data2, on=['key1', 'key2'], how='outer')\n",
    "print(\"\\nTask 14 - Merge with Different Columns:\\n\", merge_diff_columns)\n",
    "\n",
    "# Task 15\n",
    "df1 = pd.DataFrame({'A': [None, 0.0, None], 'B': [3, 4, 5]})\n",
    "df2 = pd.DataFrame({'A': [1, 1, 3], 'B': [3, None, 3]})\n",
    "combined_fill_null = df1.combine_first(df2)\n",
    "print(\"\\nTask 15 - Combined DataFrame with Filled Nulls:\\n\", combined_fill_null)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T20:59:37.277536500Z",
     "start_time": "2024-03-14T20:59:35.538247900Z"
    }
   },
   "id": "dccce854a08b0bf",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4b57963d9c282a81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
